\relax 
\citation{Rothgangl2021}
\citation{Musunuru2021}
\citation{Przybyla2021}
\citation{Dixit2016}
\citation{Datlinger2017}
\citation{Morris2021a}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and analysis challenges}{3}}
\citation{Lin2021}
\citation{Lause2021}
\citation{Townes2019}
\citation{Grun2008}
\citation{Ibrahim1990}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related work}{4}}
\citation{Barry2020}
\citation{Dixit2016}
\citation{Yang2019}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Overview of experimental design and analysis challenges}: \textbf  {a,} Experimental design. For a given perturbation (e.g., the perturbation represented in yellow), we partition the cells into two groups: those that received the perturbation, and those that did not receive the perturbation. For a given gene, we conduct a differential expression analysis across the two groups of cells, yielding an estimate of the impact of the given perturbation on the given gene. \textbf  {b,} DAG representing the variables in the analysis. The perturbation (unobserved) affects both gene expression and gRNA expression; technical factors (e.g., batch, sequencing depth, etc.) act as nuisance variables. The target of inference is the effect of the perturbation on gene expression (denoted with question mark). \textbf  {c,} Schematic illustrating ``background reads.'' The gRNA modality has a nonzero, ``background read'' distribution even in the absence of a perturbation, complicating the assignment of perturbations to cells. \textbf  {d}, Example data for a given perturbation-gene pair. Notice that (i) the perturbations are unobserved, and (ii) the gene and gRNA expression data take the form of discrete counts.}}{5}}
\newlabel{analysis_challenges}{{1}{5}}
\citation{Sarkar2021}
\@writefile{toc}{\contentsline {section}{\numberline {4}Thresholding method}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Empirical analysis}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Empirical challenges of thresholded regression.}}}{8}}
\newlabel{thresholding_empirical}{{2}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Theoretical analysis}{8}}
\newlabel{sec:thresholding_theory}{{4.2}{8}}
\newlabel{theoretical_model}{{1}{9}}
\newlabel{prop:convergence}{{1}{9}}
\newlabel{thresh_est_intercepts}{{2}{9}}
\citation{Stefanski2000a}
\newlabel{prop:att_bias}{{2}{10}}
\newlabel{prop:monotonic}{{3}{10}}
\newlabel{prop:bayes_opt}{{4}{11}}
\newlabel{prop:c_limit_half}{{5}{11}}
\newlabel{prop:comparison}{{6}{11}}
\newlabel{prop:c_limit}{{7}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Theoretical challenges of thresholded regression.} \textbf  {a,} Asymptotic relative bias versus threshold for different values of $\beta ^g_1$. The bias function is highly nonconvex and strictly nonzero. Vertical blue lines, Bayes-optimal decision boundaries. Across all panels, $\beta ^g_0 = 0$ and $\pi = 1/2$. \textbf  {b,} Asymptotic relative bias versus $\pi $ when the threshold is set to a large number. The two quantities coincide exactly. \textbf  {c,} Bias-variance decomposition for thresholding method in no-intercept model. Bias decreases and variance increases as the threshold tends to infinity. $\beta ^g_1 = 1, \beta ^m_1 = 1,$ and $\pi = 0.1$.}}{13}}
\newlabel{thresholding_theoretical}{{3}{13}}
\newlabel{theoretical_model_no_int}{{3}{13}}
\newlabel{thresh_estimator_no_int}{{4}{14}}
\newlabel{prop:bv_decomp}{{8}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {5}GLM-EIV}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Simulation studies}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Real data analysis}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Discussion}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Appendix}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Theoretical details for thresholding estimator}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.1}Notation}{15}}
\newlabel{sec:notation}{{9.1.1}{15}}
\citation{fitzpatrick2009}
\newlabel{def_g}{{5}{16}}
\newlabel{def_h}{{6}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.2}Almost sure limit of $\mathaccentV {hat}05E{\beta }^m_1$}{16}}
\newlabel{sec:convergence}{{9.1.2}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.3}Re-expressing $\gamma $ in a simpler form}{18}}
\newlabel{sec:simplication}{{9.1.3}{18}}
\newlabel{thm:gamma_expression_1}{{7}{18}}
\newlabel{thm:gamma_expression_2}{{8}{18}}
\newlabel{thm:gamma_expression_3}{{9}{18}}
\newlabel{thm:gamma_expression_4}{{10}{18}}
\newlabel{gamma_alternative}{{11}{18}}
\newlabel{gamma_alternative_pi_half}{{12}{18}}
\newlabel{gamma_alt2_pi_half}{{13}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.4}Derivatives of $g$ and $h$ in $c$}{19}}
\newlabel{sec:derivatives}{{9.1.4}{19}}
\newlabel{dg_dc}{{14}{19}}
\newlabel{dh_dc}{{15}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.5}Limit of $\gamma $ in $c$}{19}}
\newlabel{sec:c_limit}{{9.1.5}{19}}
\newlabel{c_limit_product}{{16}{20}}
\newlabel{c_limit_product_2}{{17}{20}}
\newlabel{c_limit_product_3}{{18}{20}}
\newlabel{c_limit_product_4}{{19}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.6}Bayes-optimal decision boundary as a critical value of $\gamma $}{21}}
\newlabel{sec:bayes_opt}{{9.1.6}{21}}
\newlabel{quotient_rule}{{20}{21}}
\newlabel{dg_dc_bayes}{{21}{21}}
\newlabel{dh_dc_bayes}{{22}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.7}Comparing Bayes-optimal decision boundary and large threshold}{22}}
\newlabel{sec:comparison}{{9.1.7}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.8}Monotonicity in $\beta ^g_1$}{23}}
\newlabel{sec:monotone}{{9.1.8}{23}}
\newlabel{basic_ineq_cp}{{23}{23}}
\newlabel{basic_ineq_cp_2}{{24}{23}}
\newlabel{basic_ineq_cp_3}{{25}{23}}
\newlabel{dg_dbeta}{{26}{24}}
\newlabel{dh_dbeta}{{27}{24}}
\newlabel{basic_ineq_cp_4}{{28}{24}}
\newlabel{def_2g}{{29}{24}}
\newlabel{def_4h}{{30}{24}}
\newlabel{basic_ineq_cp_5}{{31}{25}}
\newlabel{d_gamma_d_beta}{{32}{25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.9}Strict attenuation bias}{25}}
\newlabel{sec:att_bias}{{9.1.9}{25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.10}Bias-variance decomposition in no-intercept model}{26}}
\newlabel{sec:bv_decomp}{{9.1.10}{26}}
\newlabel{bc_decomp_1}{{33}{26}}
\bibstyle{unsrt}
\newlabel{bv_decomp_2}{{34}{27}}
\newlabel{bv_decomp_3}{{35}{27}}
\newlabel{bv_decomp_4}{{36}{27}}
\newlabel{bv_decomp_5}{{37}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Derivation of EM algorithm}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Derivation of observed information matrix}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Implementation using R family objects}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5}Statistical accelerations to GLM-EIV}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.6}Additional simulation results}{27}}
\bibdata{/Users/timbarry/optionFiles/glmeiv.bib}
\bibcite{Rothgangl2021}{1}
\bibcite{Musunuru2021}{2}
\bibcite{Przybyla2021}{3}
\bibcite{Dixit2016}{4}
\bibcite{Datlinger2017}{5}
\bibcite{Morris2021a}{6}
\bibcite{Lin2021}{7}
\bibcite{Lause2021}{8}
\bibcite{Townes2019}{9}
\bibcite{Grun2008}{10}
\bibcite{Ibrahim1990}{11}
\bibcite{Barry2020}{12}
\bibcite{Yang2019}{13}
\bibcite{Sarkar2021}{14}
\bibcite{Stefanski2000a}{15}
\bibcite{fitzpatrick2009}{16}
