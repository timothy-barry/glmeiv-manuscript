\relax 
\citation{Rothgangl2021}
\citation{Musunuru2021}
\citation{Przybyla2021}
\citation{Dixit2016}
\citation{Datlinger2017}
\citation{Morris2021a}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\citation{Lin2021}
\citation{Lause2021}
\citation{Townes2019}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and analysis challenges}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Related work}{3}}
\citation{Grun2008}
\citation{Ibrahim1990}
\citation{Barry2020}
\citation{Candes2018}
\citation{Liu2021}
\citation{Dixit2016}
\citation{Yang2019}
\citation{Gasperini2019}
\citation{Datlinger2021}
\citation{Mimitou2019}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Experimental design and analysis challenges}: \textbf  {a,} Experimental design. For a given perturbation (e.g., the perturbation indicated in blue), we partition the cells into two groups: perturbed and unperturbed. Next, for a given gene, we conduct a differential expression analysis across the two groups, yielding an estimate of the impact of the given perturbation on the given gene. \textbf  {b,} DAG representing all variables in the system. The perturbation (latent) impacts both gene expression and gRNA expression; technical factors act as nuisance variables, also impacting gene and gRNA expression. The target of estimation is the effect of the perturbation on gene expression. \textbf  {c,} Schematic illustrating the ``background read'' phenomenon. Due to errors in the sequencing process, unperturbed cells exhibit a nonzero gRNA count distribution (bottom). The target of estimation is the change in mean gene expression in response to the perturbation (top). \textbf  {d}, Example data on four cells for a given perturbation-gene pair. Note that (i) the perturbation is unobserved, and (ii) the gene and gRNA data are discrete counts.}}{5}}
\newlabel{analysis_challenges}{{1}{5}}
\citation{Gallagher2018}
\citation{Gasperini2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Assay overview}{6}}
\citation{Replogle2020}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Analysis challenges}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Thresholding method}{8}}
\newlabel{thresh_glm}{{1}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Empirical challenges of thresholding method}{9}}
\newlabel{sec:thresholding_empirical}{{3.1}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Empirical challenges of thresholded regression.} \textbf  {a-b,} Fold change estimates produced by threshold = 1 versus threshold = 5 (a) and threshold = 20 versus threshold = 5 (b). The selected threshold substantially impacts the results. \textbf  {c-d,} $p$-values (c) and CI widths (d) produced by threshold = 20 versus threshold = 5. The latter threshold yields more confident estimates. \textbf  {e-f}, Empirical distribution of randomly-selected gRNA from Gasperini (e) and Xie (f) data (0 counts not shown). The gRNA data do not appear to imply an obvious threshold selection strategy.}}{11}}
\newlabel{thresholding_empirical}{{2}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Theoretical challenges of thresholding method}{12}}
\newlabel{sec:thresholding_theory}{{3.2}{12}}
\newlabel{theoretical_model}{{2}{12}}
\newlabel{prop:convergence}{{1}{12}}
\newlabel{thresh_est_intercepts}{{3}{12}}
\citation{Stefanski2000a}
\newlabel{prop:att_bias}{{2}{13}}
\newlabel{prop:monotonic}{{3}{14}}
\newlabel{prop:bayes_opt}{{4}{14}}
\newlabel{prop:c_limit_half}{{5}{14}}
\newlabel{prop:comparison}{{6}{14}}
\newlabel{prop:c_limit}{{7}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Theoretical challenges of thresholded regression.} \textbf  {a,} Asymptotic relative bias versus threshold for different values of $\beta ^g_1$. The bias function is highly nonconvex and strictly nonzero. Vertical blue lines, Bayes-optimal decision boundaries. Across all panels, $\beta ^g_0 = 0$ and $\pi = 1/2$. \textbf  {b,} Asymptotic relative bias versus $\pi $ when the threshold is set to a large number. The two quantities coincide exactly. \textbf  {c,} Bias-variance decomposition for thresholding method in no-intercept model. Bias decreases and variance increases as the threshold tends to infinity. $\beta ^g_1 = 1, \beta ^m_1 = 1,$ and $\pi = 0.1$.}}{16}}
\newlabel{thresholding_theoretical}{{3}{16}}
\newlabel{theoretical_model_no_int}{{4}{17}}
\newlabel{thresh_estimator_no_int}{{5}{17}}
\newlabel{prop:bv_decomp}{{8}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Thresholding method summary}{17}}
\citation{Townes2019}
\citation{Svensson2020}
\citation{Hafemeister2019}
\citation{Sarkar2021}
\@writefile{toc}{\contentsline {section}{\numberline {4}Generalized linear model with errors in variables}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Model}{18}}
\newlabel{glmeiv_model_1}{{6}{18}}
\newlabel{glmeiv_model_2}{{7}{18}}
\citation{Datlinger2017}
\citation{Hill2018}
\newlabel{glmeiv_model_3}{{8}{19}}
\newlabel{glmeiv_model_4}{{9}{19}}
\newlabel{glmeiv_model_5}{{10}{19}}
\newlabel{full_density}{{11}{21}}
\newlabel{full_log_lik}{{12}{21}}
\citation{Ibrahim1990}
\newlabel{marginal_density}{{13}{22}}
\newlabel{marginal_log_lik}{{14}{22}}
\newlabel{classical_eiv}{{15}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Estimation and inference}{22}}
\citation{Louis2012}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces EM algorithm for GLM-EIV model.}}{23}}
\newlabel{algo:em_full}{{1}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Statistical accelerations}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Simulation studies}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Real data analysis}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{24}}
\@writefile{toc}{\contentsline {section}{Appendices}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Theoretical details for thresholding estimator}{24}}
\citation{fitzpatrick2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Notation}{25}}
\newlabel{sec:notation}{{A.1}{25}}
\newlabel{def_g}{{16}{25}}
\newlabel{def_h}{{17}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Almost sure limit of $\mathaccentV {hat}05E{\beta }^m_1$}{26}}
\newlabel{sec:convergence}{{A.2}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Re-expressing $\gamma $ in a simpler form}{27}}
\newlabel{sec:simplication}{{A.3}{27}}
\newlabel{thm:gamma_expression_1}{{18}{27}}
\newlabel{thm:gamma_expression_2}{{19}{27}}
\newlabel{thm:gamma_expression_3}{{20}{27}}
\newlabel{thm:gamma_expression_4}{{21}{27}}
\newlabel{gamma_alternative}{{22}{27}}
\newlabel{gamma_alternative_pi_half}{{23}{27}}
\newlabel{gamma_alt2_pi_half}{{24}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4}Derivatives of $g$ and $h$ in $c$}{28}}
\newlabel{sec:derivatives}{{A.4}{28}}
\newlabel{dg_dc}{{25}{28}}
\newlabel{dh_dc}{{26}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.5}Limit of $\gamma $ in $c$}{28}}
\newlabel{sec:c_limit}{{A.5}{28}}
\newlabel{c_limit_product}{{27}{29}}
\newlabel{c_limit_product_2}{{28}{29}}
\newlabel{c_limit_product_3}{{29}{29}}
\newlabel{c_limit_product_4}{{30}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.6}Bayes-optimal decision boundary as a critical value of $\gamma $}{30}}
\newlabel{sec:bayes_opt}{{A.6}{30}}
\newlabel{quotient_rule}{{31}{30}}
\newlabel{dg_dc_bayes}{{32}{30}}
\newlabel{dh_dc_bayes}{{33}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.7}Comparing Bayes-optimal decision boundary and large threshold}{31}}
\newlabel{sec:comparison}{{A.7}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.8}Monotonicity in $\beta ^g_1$}{31}}
\newlabel{sec:monotone}{{A.8}{31}}
\newlabel{basic_ineq_cp}{{34}{32}}
\newlabel{basic_ineq_cp_2}{{35}{32}}
\newlabel{basic_ineq_cp_3}{{36}{32}}
\newlabel{dg_dbeta}{{37}{33}}
\newlabel{dh_dbeta}{{38}{33}}
\newlabel{basic_ineq_cp_4}{{39}{33}}
\newlabel{def_2g}{{40}{33}}
\newlabel{def_4h}{{41}{33}}
\newlabel{basic_ineq_cp_5}{{42}{33}}
\newlabel{d_gamma_d_beta}{{43}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.9}Strict attenuation bias}{34}}
\newlabel{sec:att_bias}{{A.9}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.10}Bias-variance decomposition in no-intercept model}{35}}
\newlabel{sec:bv_decomp}{{A.10}{35}}
\newlabel{bc_decomp_1}{{44}{35}}
\newlabel{bv_decomp_2}{{45}{36}}
\newlabel{bv_decomp_3}{{46}{36}}
\newlabel{bv_decomp_4}{{47}{36}}
\newlabel{bv_decomp_5}{{48}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Estimation and inference in the GLM-EIV model}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1}Estimation}{36}}
\newlabel{Q_funct}{{49}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2}Inference}{39}}
\citation{Louis1982}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Block structure of the observed information matrix $J(\theta ; m, g) = -\nabla ^2 \mathcal  {L}(\theta ; m, g)$. The matrix is symmetric, and so we only need to compute submatrices I-VI to compute the entire matrix.}}{41}}
\newlabel{infomatrixbackground}{{4}{41}}
\newlabel{zero_inf_info_mat}{{50}{41}}
\newlabel{sub_mat_pi}{{51}{41}}
\newlabel{d_L_d_pi}{{52}{42}}
\newlabel{submat_pi_1}{{53}{42}}
\newlabel{submat_pi_2}{{54}{43}}
\newlabel{sub_mat_1_formula}{{55}{43}}
\newlabel{sub_mat_2}{{56}{44}}
\newlabel{sub_mat_2_1}{{57}{44}}
\newlabel{sub_mat_2_2}{{58}{46}}
\newlabel{sub_mat_2_formula}{{59}{46}}
\newlabel{sub_mat_3_formula}{{60}{46}}
\newlabel{sub_mat_4}{{61}{47}}
\newlabel{sub_mat_4_1}{{62}{47}}
\newlabel{sub_mat_4_2}{{63}{48}}
\newlabel{sub_mat_4_formula}{{64}{48}}
\newlabel{sub_mat_5}{{65}{49}}
\newlabel{sub_mat_5_1}{{66}{49}}
\newlabel{sub_mat_5_2}{{67}{50}}
\newlabel{sub_mat_5_formula}{{68}{50}}
\newlabel{sub_mat_6_formula}{{69}{50}}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3}Implementation}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Statistical accelerations}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Additional simulation results}{52}}
\bibdata{/Users/timbarry/optionFiles/glmeiv.bib}
\bibcite{Rothgangl2021}{1}
\bibcite{Musunuru2021}{2}
\bibcite{Przybyla2021}{3}
\bibcite{Dixit2016}{4}
\bibcite{Datlinger2017}{5}
\bibcite{Morris2021a}{6}
\bibcite{Lin2021}{7}
\bibcite{Lause2021}{8}
\bibcite{Townes2019}{9}
\bibcite{Grun2008}{10}
\bibcite{Ibrahim1990}{11}
\bibcite{Barry2020}{12}
\bibcite{Candes2018}{13}
\bibcite{Liu2021}{14}
\bibcite{Yang2019}{15}
\bibcite{Gasperini2019}{16}
\bibcite{Datlinger2021}{17}
\bibcite{Mimitou2019}{18}
\bibcite{Gallagher2018}{19}
\bibcite{Gasperini2020}{20}
\bibcite{Replogle2020}{21}
\bibcite{Stefanski2000a}{22}
\bibcite{Svensson2020}{23}
\bibcite{Hafemeister2019}{24}
\bibcite{Sarkar2021}{25}
\bibcite{Hill2018}{26}
\bibcite{fitzpatrick2009}{27}
\bibcite{Louis1982}{28}
